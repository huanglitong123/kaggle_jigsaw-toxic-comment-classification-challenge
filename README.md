# kaggle_jigsaw-toxic-comment-classification-challenge
kaggle jigsaw-toxic-comment-classification-challenge
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
初做文本比赛
尝试了LR,NB,SVM,LGB,LSTM,GRU
深度学习较LR之类的效果要好
尝试不同GRU比lstm好些
glove比fasttest好些

关键文件，GRU_fasttext.py是核心
NLP_model.py是测试模型用的

缺点：
1. 测试模型时候，没加KFOLD,结果会存在抖动，无法准确检验模型准确性
2. 在选用机器学习模型时候，缺少不断尝试的努力，只是简单的测试，然后选用最好的模型
3. 在深度学习模型中，没有建立快速调参的方法（缺乏设备）
4. 缺少记录日志
5. 缺少对模型变好变坏的分析和预测
6. 对自己新想法的实施通常比较慢

本次比赛总结：
特征：
文本不仅存在逻辑规则，还存在经验规则。统计学上大部分采用的是经验规则，例如词出现次数等等。这是一类。
文本有很多规律可以挖掘，与此对应的就是不同的文本处理方式，例如标点符号重复可能代表强调，那如果去掉，就损失了信息，
因此不同的文本处理，对应不同的规则，而不同的规则很可能能走到同一条路上去。

TF-IDF（word，char）是用的词频-文频的规则
LSTM收集的是前后文关系规则
其他特征工程（独特词个数，文本长短）也是一个规则
文本中无数个规则，互相组合形成规则群，也就是特征群

模型：
不同的模型有不一样的偏好和适用性，有个喜欢这样的规则，有的喜欢那样的
树模型xgboost，图模型，NN模型RNN，线性模型LR,SVM
不同模型对于不同特征有不同的适用性，也或有强弱。模型与特征群的组合，产生的结果就是我们想要的答案。

模型融合：
不同模型对同种特征的理解和运算，然后融合，其实对结果的影响没有作用，因为是同样的学习方式去学同一个东西。例如xgboost和lightgbm，理解方式相同，学出来的东西，自然相似。
模型对规则的理解和匹配决定了模型的好坏，规则是不全的，模型学习能力也不是完美的，因此和结果总会存在距离。而不同模型对不同规则的学习的融合，或许是数学去理解混沌的一种方式。
多个无限接近，使得更加无限接近。

这大概就是工程和比赛的道吧！

这次比赛也学了很多技巧。慢慢总结更新。
